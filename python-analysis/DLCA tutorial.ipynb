{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLCA\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Package\n",
    "\n",
    "You must have a least two files in order to use DLCA\n",
    "- the executable DLCA (which should works on any linux)\n",
    "- a parameter file params.txt\n",
    "\n",
    "Eventually you can also have:\n",
    "- DLCA_Reader.py, wich allows you to read DLCA output in python\n",
    "\n",
    "The rest is just a demo:\n",
    "- blender.py, wich allows you to export DLCA data to blender\n",
    "- DLCA tutorial.ipynb this file\n",
    "- Analyze.ipynb, a jupyter notebook that shows you more exemple of data processing\n",
    "- Analyze_cython.pyx wich contains some analyzing tools in cython\n",
    "\n",
    "Just to be clear, DLCA is not a python application,  \n",
    "Python is only used for postprocessing and this tutorial\n",
    "\n",
    "Sorry if everything has not been translated to english yet\n",
    "\n",
    "### What does it do ?\n",
    "\n",
    "1. We initialize some spheres in a box (random position and size)  \n",
    "   At first each sphere is one aggregate  \n",
    "2. We pick randomly an aggregate\n",
    "3. We move the aggregate in a random direction for\n",
    " - its mean free path\n",
    " - or until there is a collision\n",
    "4. In case of a collision, we merge the aggregates\n",
    "5. loop to 2. until we meet some criteria\n",
    "\n",
    "### What does it output\n",
    "\n",
    "Every time there is a collision, it output in some binary files\n",
    "- For every spheres:\n",
    "    - position\n",
    "    - radius\n",
    "    - aggregate label\n",
    "    \n",
    "    \n",
    "- For every aggregate\n",
    "    - mass center position\n",
    "    - number of spheres\n",
    "    - mobility diameter\n",
    "    - gyration radius\n",
    "    - mean free path\n",
    "    - geometric radius\n",
    "    - estimation of the volume\n",
    "    - estimation of the surface\n",
    "    - label\n",
    "    \n",
    "### dependencies\n",
    "- For DLCA: nothing (hopefully the binary should work out of the box, but I'm not sure...) \n",
    "- For post processing:\n",
    "  - paraview  (if you want)\n",
    "  - blender   (if you want)\n",
    "  - python    (you should want that)\n",
    "    - jupyter     (for the notebooks)\n",
    "    - h5py        (in order to read DLCA output)\n",
    "    - lxml        (in order to read DLCA output)\n",
    "    - numpy       (for almost everything)\n",
    "    - pandas      (for everything)\n",
    "    - matplotlib  (for plotting)\n",
    "    - cython      (for some advanced analysis tools)\n",
    "    - scipy        \n",
    "    - scikit-image\n",
    "    - scikit-learn\n",
    "\n",
    "## How to use it\n",
    "\n",
    "### Parameter file\n",
    "The parameter file looks like that :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat params.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every element of the first column is mandatory in this order.  \n",
    "Everything else is just comments and are optional.  \n",
    "The second column is the name of the parameter.  \n",
    "The third column is the unit if the parameter.\n",
    "\n",
    "### Execution\n",
    "You can execute the program like any other program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!./DLCA params.txt\n",
    "!../build-Generateur_DLCA/release/DLCA params.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output \n",
    "\n",
    "On the screen, it will output after every collision:\n",
    "- NAgg is the current number of aggregate, at first it is the number of spheres and decrease one by one\n",
    "- temps is the physical time (at least statisticly)\n",
    "- CPU is the computational time (in seconds)\n",
    "- after n it is the nuber of time iteration without collision that precedes this one\n",
    "\n",
    "It will also produce some **files.h5** and **files.xmf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each **file.xmf** is an ascii xml file explaining the content of each binary hdf5 **file.h5**\n",
    "Each pair **xmf+h5** contains multiples times steps in order to avoid having to many files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head -n40 output_dir/Aggregats_0000000.xmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First it reminds the phyiscal parameters, and then for each time step where to find what in the file.h5\n",
    "\n",
    "## Post processing\n",
    "### paraview\n",
    "The xmf files are natively readable by paraview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!paraview output_dir/Spheres_..xmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the spheres:\n",
    "0. apply\n",
    "1. add a **glyph** filter\n",
    "2. glyph type: **sphere**\n",
    "3. advanced : glyph radius: **1**\n",
    "4. scaling mode: **scalar**\n",
    "5. scale factor: **1**\n",
    "6. apply\n",
    "7. reset camera (in order to auto scale)\n",
    "\n",
    "### blender\n",
    "I made a little python script for that (almost no tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!blender -P blender.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just delete the big square and you should be able to do everything you want\n",
    "\n",
    "### python\n",
    "\n",
    "We provide a script **DLCA_Reader** that is able to read the data and put it in a pandas format for python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from DLCA_Reader import DLCA\n",
    "\n",
    "# The folder with all .h5 and .xmf files\n",
    "data_dir = Path(\"output_dir/\")\n",
    "\n",
    "# Read all data\n",
    "Spheres, Aggregates = DLCA(data_dir).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Spheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Aggregates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Analyze notebook show more of what type of analysis is possible\n",
    "\n",
    "**Have Fun !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
