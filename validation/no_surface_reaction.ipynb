{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to validate MCAC after major modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Parameters](#Parameters)\n",
    "2. [Read and compute](#Read_and_compute)\n",
    "3. [Results](#Results)\n",
    "    1. [Residence time](#Residence_time)\n",
    "    2. [Volume fraction](#Volume_fraction)\n",
    "    3. [Diffusion coefficient](#Diffusion_coefficient)\n",
    "    4. [Particle number concentration](#Particle_number_concentration)\n",
    "    5. [Gas Knudsen number](#Knudsen)\n",
    "    6. [Radius of gyration](#gyration)\n",
    "    7. [Aggregate polydispersity](#polydispersity)\n",
    "    8. [Total energy](#energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"Introduction\"></a>\n",
    "\n",
    "This Python script aims at validating MCAC by comparing with a 'well known' case already simulated in a previous version of the code (published results). This is referred as \"ref_case\" compared with the new simulation \"new_case\".\n",
    "\n",
    "In this particular code only coagulation takes place without other mechanisms of particle growth or nucleation. The aspects of the code to be validated are: the mobility (diffusion coefficient D), kinetics of aggregation (number of clusters: Nc, the size of the box: L_box, and the particle number concentration: N), flow regime (Gas Knudsen number) morpholoogy (Rg vs. Np, fractal dimension and prefactor), and aggregate polydispersity (GSD of Dv). Finally, the conservation of energy (only kinetic since interaction potential are not simulated) is tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display\n",
    "\n",
    "from pymcac import dask_distribute\n",
    "from pymcac import MCAC\n",
    "from pymcac import groupby_agg\n",
    "from pymcac import progress_compute\n",
    "from pymcac import mobility_diameter\n",
    "from pymcac.tools.core.groupby import groupby_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_quantities(xAggregates, xSpheres):\n",
    "\n",
    "    xAggregates[\"log_Rv\"] = np.log((6 * xAggregates.Volume / np.pi)) / 3\n",
    "    xAggregates[\"Ec\"] = 0.5 * xAggregates.Volume * rhop_0 * (xAggregates.lpm / xAggregates.Deltat) ** 2\n",
    "\n",
    "    xAggregates[\"Dm\"] = mobility_diameter(xAggregates.f_agg,\n",
    "                           A1=A1, A2=A2, A3=A3, lambda_g=lambda_g, mu_g=mu_g)\n",
    "    xAggregates[\"Kn\"] = 2 * lambda_g / xAggregates[\"Dm\"]\n",
    "\n",
    "    # does the job, only slower\n",
    "#     xMeanRp = groupby_aggregate(xSpheres, xAggregates,\n",
    "#                                 np.mean,\n",
    "#                                 [\"Radius\"],\n",
    "#                                 {\"MeanRp\": np.float64})\n",
    "    xMeanRp = groupby_agg(xSpheres,\n",
    "                          by=[\"Time\", \"Label\"],\n",
    "                          agg=[(\"Radius\", \"mean\", \"Radius\")],\n",
    "                          index_arrays=[xAggregates.kTime, xAggregates.kLabel])\n",
    "    # rechunking to align xMeanRp on xAggregates\n",
    "    xMeanRp = xMeanRp.chunk({\"k\": xAggregates.chunks[\"k\"]})\n",
    "    # using xMeanRp.data avoid triggering a computation\n",
    "    # due to possibly misaligned coordinates\n",
    "    # (groupby_agg sorts by default so this can be skipped)\n",
    "    xAggregates[\"DgOverDp\"] = xAggregates.Rg / xMeanRp.data\n",
    "\n",
    "    return xAggregates, xSpheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_averaged_quantities(xAggregates, xSpheres):\n",
    "\n",
    "    time_averaged = groupby_agg(xAggregates,\n",
    "                                by=\"Time\",\n",
    "                                index_arrays=xAggregates.Time,\n",
    "                                agg=[\n",
    "        (\"f_agg\", \"mean\",\"f_agg\"),\n",
    "        (\"Np\", \"mean\",\"Np\"),\n",
    "        (\"Rg\", \"mean\",\"Rg\"),\n",
    "        (\"DgOverDp\", \"mean\",\"DgOverDp\"),\n",
    "        (\"Dm\", \"mean\",\"Dm\"),\n",
    "        (\"Kn\", \"mean\",\"Kn\"),\n",
    "        (\"Nc\", \"size\",\"Np\"),\n",
    "        (\"Ec\", \"sum\",\"Ec\"),\n",
    "        (\"fv\", \"sum\",\"Volume\"),\n",
    "        (\"Rv_geo\", \"mean\",\"log_Rv\"),\n",
    "        (\"sv_geo\", \"std\",\"log_Rv\")\n",
    "    ])\n",
    "    time_averaged[\"BoxSize\"] = xAggregates.BoxSize.chunk({\"Time\": -1})\n",
    "    BoxVolume = time_averaged.BoxSize ** 3\n",
    "    time_averaged[\"fv\"] /= BoxVolume\n",
    "    time_averaged[\"Rv_geo\"] = np.exp(time_averaged.Rv_geo)\n",
    "    time_averaged[\"sv_geo\"] = np.exp(time_averaged.sv_geo)\n",
    "\n",
    "    time_averaged[\"Nc density\"] = time_averaged.Nc / BoxVolume\n",
    "    time_averaged[\"Diffusion\"] = k_B * T_g / time_averaged.f_agg\n",
    "\n",
    "    time_averaged[\"Dm_avg\"] = mobility_diameter(time_averaged.f_agg,\n",
    "                                                A1=A1, A2=A2, A3=A3, lambda_g=lambda_g, mu_g=mu_g)\n",
    "    time_averaged[\"Kn_avg\"] = 2 * lambda_g / time_averaged[\"Dm_avg\"]\n",
    "\n",
    "    xMeanRp = groupby_agg(xSpheres,\n",
    "                          by=\"Time\",\n",
    "                          agg=[(\"Radius\", \"mean\", \"Radius\")],\n",
    "                          index_arrays=xSpheres.Time,)\n",
    "    # rechunking to align xMeanRp on xAggregates\n",
    "    xMeanRp = xMeanRp.chunk({\"Time\": xAggregates.chunks[\"Time\"]})\n",
    "    # using xMeanRp.data avoid triggering a computation\n",
    "    # due to possibly misaligned coordinates\n",
    "    # (groupby_agg sorts by default so this can be skipped)\n",
    "    time_averaged[\"DgOverDp_avg\"] = time_averaged.Rg / xMeanRp.data\n",
    "\n",
    "    return time_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(ds, tmax=None, ncmax=None, ts=None):\n",
    "    if all(v is not None for v in (tmax, ncmax, ts)):\n",
    "        # nothing to filter\n",
    "        return ds\n",
    "    \n",
    "    ds_k = ds.drop_dims((dim for dim in ds.dims if dim != \"k\"))\n",
    "    ds_t = ds.drop_dims((dim for dim in ds.dims if dim != \"Time\"))\n",
    "    ds_l = ds.drop_dims((dim for dim in ds.dims if dim != \"Label\"))\n",
    "    \n",
    "    if ts is not None or tmax is not None:\n",
    "        if ts is not None:\n",
    "            mask_k = ds_k.kTime.isin(ts)\n",
    "            mask_t = ds_t.Time.isin(ts)\n",
    "        else:\n",
    "            mask_k = ds_k.kTime < tmax\n",
    "            mask_t = ds_t.Time < tmax\n",
    "\n",
    "#         print(ds_k)\n",
    "#         print(mask_k)\n",
    "        ds_k = ds_k.where(mask_k, drop=True)\n",
    "        ds_t = ds_t.where(mask_t, drop=True)\n",
    "        \n",
    "    if ncmax is not None:\n",
    "        mask_k = mask_k & (ds_k.kLabel < ncmax)\n",
    "        mask_l = mask_l & (ds_l.kLabel < ncmax)\n",
    "        \n",
    "        ds_l = ds_l.where(mask_l, drop=True)\n",
    "    \n",
    "    return xr.merge([ds_t, ds_k, ds_l], combine_attrs=\"identical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path, tmax=None, ncmax=None, nt=None):\n",
    "    # The folder with all .h5 and .xmf files\n",
    "    MCACSimulation = MCAC(path)\n",
    "\n",
    "    # Read all data\n",
    "    xSpheres = MCACSimulation.xspheres\n",
    "    xAggregates = MCACSimulation.xaggregates\n",
    "    \n",
    "    # filter data (keeping only some time step and/or some aggregates)\n",
    "    ts = None\n",
    "    if nt is not None:\n",
    "        if tmax is None:\n",
    "            tmax = MCACSimulation.times[-1]\n",
    "        times = np.linspace(MCACSimulation.times[0], tmax, nt)\n",
    "        idx = np.unique((MCACSimulation.times<times[:,np.newaxis]).argmin(axis=1))\n",
    "        ts = MCACSimulation.times[idx]\n",
    "\n",
    "    xSpheres = filtering(xSpheres, tmax=tmax, ncmax=ncmax, ts=ts)\n",
    "    xAggregates = filtering(xAggregates, tmax=tmax, ncmax=ncmax, ts=ts)\n",
    "\n",
    "    # Per aggregate computations\n",
    "    xAggregates, xSpheres = add_missing_quantities(xAggregates, xSpheres)\n",
    "\n",
    "    # Per time-step computations\n",
    "    time_averaged = time_averaged_quantities(xAggregates, xSpheres)\n",
    "\n",
    "    return MCACSimulation, time_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(ds1, ds2, x, y, xlabel=None, ylabel=None, **kwargs):\n",
    "    fig = plt.figure(figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    fig.set_tight_layout(False)\n",
    "\n",
    "    kwargs[\"ax\"] = kwargs.get(\"ax\", plt.gca())\n",
    "\n",
    "    if x is None:\n",
    "        x = next(iter(ds1.coords))\n",
    "\n",
    "    if isinstance(y, str):\n",
    "        y = [y]\n",
    "\n",
    "    if isinstance(ds1, xr.DataArray):\n",
    "        ds1 = ds1.to_dataset()\n",
    "    if isinstance(ds2, xr.DataArray):\n",
    "        ds2 = ds2.to_dataset()\n",
    "\n",
    "    df1 = ds1[[x]+y].to_dataframe()\n",
    "    df2 = ds2[[x]+y].to_dataframe()\n",
    "\n",
    "    if x in df1.columns:\n",
    "        df1 = df1.set_index(x)\n",
    "        df2 = df2.set_index(x)\n",
    "    df1 = df1.sort_index()\n",
    "    df2 = df2.sort_index()\n",
    "\n",
    "    df1.plot(**kwargs, style=\"-\")\n",
    "    df2.plot(**kwargs, style=\"--\")\n",
    "\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel)\n",
    "\n",
    "    plt.legend([f\"New {varname}\" for varname in y] + [f\"Ref {varname}\" for varname in y])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters <a class=\"anchor\" id=\"Parameters\"></a>\n",
    "\n",
    "Check these parameters before running the script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_g = 1_700  # temperature in K\n",
    "P_g = 101_300  # pressure in Pa\n",
    "rhop_0 = 1_800  # particle bulk density in kg/m^3\n",
    "k_B = 1.38066E-23  # Boltzmann constant in J/K\n",
    "\n",
    "# gas mean free path and viscosity\n",
    "lambda_g = 66.5E-9 * (101_300 / P_g) * (T_g / 293.15) * (1 + 110 / 293.15) / (1 + 110 / T_g)  # in m\n",
    "mu_g = 18.203E-6 * (293.15 + 110) / (T_g + 110) * (T_g / 293.15) ** 1.5  # in Ps*s\n",
    "\n",
    "# for Cunningham slip correction factor: Cc\n",
    "A1 = 1.142\n",
    "A2 = 0.558\n",
    "A3 = 0.999\n",
    "\n",
    "polydisperse = True\n",
    "if polydisperse:\n",
    "    reference_path = Path(\"/stockage/samba/Partages/public/MCAC_validation/03_VARYING_PP_polyd/03p1_SIGMAp_1p25/run1\")\n",
    "    result_path = Path(\"polydisperse_data\")\n",
    "else:\n",
    "    #reference_path = Path(\"/stockage/samba/Partages/public/MCAC_validation/02_VARYING_DP/02p3_Dp10nm_np0_3200/run1\")\n",
    "    reference_path = Path(\"/Data/WORK/Projets/SRC/MCAC/validation/monodisperse_data_ref/\")\n",
    "    result_path = Path(\"/Data/WORK/Projets/SRC/MCAC/validation/monodisperse_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and compute  <a class=\"anchor\" id=\"Read_and_compute\"></a>\n",
    "\n",
    "You can look at the dashboard to see progress in more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33853</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>33.59 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33853' processes=8 threads=8, memory=33.59 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading new\n",
      "Reading reference\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataArray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ab9ef6d44bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrefSimulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_time_averaged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3.8e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start compute\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-53527844cc59>\u001b[0m in \u001b[0;36mread\u001b[0;34m(path, tmax, ncmax, nt)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCACSimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mxSpheres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxSpheres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mncmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mxAggregates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxAggregates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mncmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c381f0722932>\u001b[0m in \u001b[0;36mfiltering\u001b[0;34m(ds, tmax, ncmax, ts)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#         print(ds_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#         print(mask_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mds_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mds_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/WORK/Projets/SRC/MCAC/venv/lib/python3.8/site-packages/xarray/core/common.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(self, cond, other, drop)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m             \u001b[0;31m# clip the data corresponding to coordinate dims that are not used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m             \u001b[0mnonzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipcond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipcond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m             \u001b[0mindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonzeros\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data/WORK/Projets/SRC/MCAC/venv/lib/python3.8/site-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;34m\"{!r} object has no attribute {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataArray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "with dask_distribute(report=True) as c:\n",
    "    display(c)\n",
    "    print(\"Reading new\")\n",
    "    newSimulation, new_time_averaged = read(result_path, tmax=3.8e-3, nt=100)\n",
    "\n",
    "    print(\"Reading reference\")\n",
    "    refSimulation, ref_time_averaged = read(reference_path, tmax=3.8e-3, nt=100)\n",
    "\n",
    "    print(\"Start compute\")\n",
    "    new_time_averaged, ref_time_averaged = progress_compute(new_time_averaged, ref_time_averaged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results <a class=\"anchor\" id=\"Results\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time_averaged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residence time <a class=\"anchor\" id=\"Residence_time\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Ref total residence time: \"\n",
    "      f\"{float(ref_time_averaged.Time[-1] - ref_time_averaged.Time[0]) * 1e3} (ms) \"\n",
    "      f\"({ref_time_averaged.Time.size} it)\")\n",
    "print(f\" New total residence time: \"\n",
    "      f\"{float(new_time_averaged.Time[-1] - new_time_averaged.Time[0]) * 1e3} (ms) \"\n",
    "      f\"({new_time_averaged.Time.size} it)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume fraction <a class=\"anchor\" id=\"Volume_fraction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" ref volume fraction = {float(ref_time_averaged.fv[0]) * 1e+06} ppm\")\n",
    "print(f\" new volume fraction = {float(new_time_averaged.fv[0]) * 1e+06} ppm\")\n",
    "plot_compare(new_time_averaged.fv * 1e+06, ref_time_averaged.fv * 1e+06,\n",
    "             x=None, xlabel=\"Time (s)\",\n",
    "             y=\"fv\", ylabel=\"volume fraction (ppm)\",\n",
    "             loglog=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion coefficient <a class=\"anchor\" id=\"Diffusion_coefficient\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of diffusion coefficients allow to check: temperature, friction coefficient,\n",
    "# fLuid viscosity. Becareful, f_agg depends on the fractal dimension!\n",
    "plot_compare(new_time_averaged, ref_time_averaged,\n",
    "             x=\"Np\", xlabel=\"Number of monomers per aggregate (mean)\",\n",
    "             y=\"Diffusion\", ylabel=\"Diffusion coefficient (m^2/s)\",\n",
    "             loglog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle number concentration <a class=\"anchor\" id=\"Particle_number_concentration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_compare(new_time_averaged, ref_time_averaged,\n",
    "#              x=None, xlabel=\"Time (s)\",\n",
    "#              y=\"Nc\", ylabel=\"Number of aggregate (-)\",\n",
    "#              loglog=True)\n",
    "# plot_compare(new_time_averaged, ref_time_averaged,\n",
    "#              x=None, xlabel=\"Time (s)\",\n",
    "#              y=\"BoxSize\", ylabel=\"Box size (m)\",\n",
    "#              loglog=True)\n",
    "plot_compare(new_time_averaged, ref_time_averaged,\n",
    "             x=None, xlabel=\"Time (s)\",\n",
    "             y=\"Nc density\", ylabel=\"Particle number concentration (-)\",\n",
    "             loglog=True)\n",
    "print(f\"Ref case initialized with {int(ref_time_averaged.Nc[0])} monomers\")\n",
    "print(f\"New case initialized with {int(new_time_averaged.Nc[0])} monomers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gas Knudsen number <a class=\"anchor\" id=\"Knudsen\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compare(new_time_averaged, ref_time_averaged,\n",
    "             x=None, xlabel=\"Time (s)\",\n",
    "             y=[\"Kn\", \"Kn_avg\"], ylabel=\"Gas Knudsen number\",\n",
    "             loglog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radius of gyration <a class=\"anchor\" id=\"gyration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to check the role played by monomer mass is correcly considered for each\n",
    "# agglomerate. Also, according to Np and the fractal dimension they should have\n",
    "# comparable values.\n",
    "plot_compare(new_time_averaged, ref_time_averaged,\n",
    "             x=\"Np\", xlabel=\"Number of monomers per aggregate (mean)\",\n",
    "             y=\"Rg\", ylabel=\"Radius of gyration (m)\",\n",
    "             loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compare(new_time_averaged, ref_time_averaged,\n",
    "             x=\"Np\", xlabel=\"Number of monomers per aggregate (mean)\",\n",
    "             y=[\"DgOverDp\", \"DgOverDp_avg\"], ylabel=\"DgOverDp\",\n",
    "             loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The population-based fractal dimension and prefactor\n",
    "# Becareful: There is variability on these parameters for individual simulations.\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(np.log(ref_time_averaged.DgOverDp_avg).values[:, np.newaxis],\n",
    "          np.log(ref_time_averaged.Np))\n",
    "print(f\"Ref fractal Law: {np.exp(model.intercept_)} x^{model.coef_[0]}\")\n",
    "\n",
    "model.fit(np.log(new_time_averaged.DgOverDp_avg).values[:, np.newaxis],\n",
    "          np.log(new_time_averaged.Np))\n",
    "print(f\"New fractal Law: {np.exp(model.intercept_)} x^{model.coef_[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate polydispersity  <a class=\"anchor\" id=\"polydispersity\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_compare(new_time_averaged, ref_time_averaged,\n",
    "             x=\"Np\", xlabel=\"Number of monomers per aggregate (mean)\",\n",
    "             y=\"Rv_geo\", ylabel=\"Geometric mean vol-eq. radius, R_v (nm)\",\n",
    "             loglog=False)\n",
    "plot_compare(new_time_averaged, ref_time_averaged,\n",
    "             x=\"Np\", xlabel=\"Number of monomers per aggregate (mean)\",\n",
    "             y=\"sv_geo\", ylabel=\"Geometric standard deviation, $\\sigma_{g,rv}$ (-)\",\n",
    "             loglog=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total energy  <a class=\"anchor\" id=\"energy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total kinetic energy of the system of $N$ particles is, $$K=\\sum_i^{N} \\frac{1}{2}m_ic_i^2$$\n",
    "where $m_i$ and $c_i=\\frac{lpm_i}{\\Delta t_i}$ are the mass and averaged velocity of the $i^{th}$ particle, respectively.\n",
    "\n",
    "From the kinetic theory of gases we have, $$\\frac{1}{2}m_ic_i^2=\\frac{3}{2}k_BT$$\n",
    "\n",
    "Therefore, the total energy is related to the temperature as, $$E_{tot}=N\\frac{3}{2}k_BT=K$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time_averaged[\"Kinetic energy per aggregate\"] = new_time_averaged.Ec / new_time_averaged.Nc\n",
    "ref_time_averaged[\"Kinetic energy per aggregate\"] = ref_time_averaged.Ec / ref_time_averaged.Nc\n",
    "\n",
    "print(f\"    kb * T = {k_B * T_g}\")\n",
    "print(f\" ref Ec/Nc = {float(ref_time_averaged['Kinetic energy per aggregate'][0])}\")\n",
    "print(f\" new Ec/Nc = {float(new_time_averaged['Kinetic energy per aggregate'][0])}\")\n",
    "\n",
    "plot_compare(new_time_averaged, ref_time_averaged,\n",
    "             x=\"Np\", xlabel=\"Number of monomers per aggregate (mean)\",\n",
    "             y=\"Kinetic energy per aggregate\", ylabel=\"Kinetic energy per aggregate\",\n",
    "             loglog=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
